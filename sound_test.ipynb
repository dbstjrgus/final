{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "recording audio ",
   "id": "5a14c0b41a0f4b76"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-17T15:49:12.028835Z",
     "start_time": "2024-12-17T15:49:06.809729Z"
    }
   },
   "source": [
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "# collect data of small user base, probably using siamese network\n",
    "def record_audio(file_name, duration = 5, sampling_rate = 16000): # sr = samples taken per second \n",
    "    print(f\"Recording audio for {duration} seconds...\")\n",
    "    audio = sd.rec(int(duration * sampling_rate), samplerate=sampling_rate, channels=1)\n",
    "    sd.wait()  # waits until the 5 second recording is done\n",
    "    sf.write(file_name, audio, sampling_rate) # saves the audio file\n",
    "    print(f\"Finished recording audio for {duration} seconds.\")\n",
    "    \n",
    "record_audio(\"5s20.wav\") # file name\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording audio for 5 seconds...\n",
      "Finished recording audio for 5 seconds.\n"
     ]
    }
   ],
   "execution_count": 228
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "clean and save audio",
   "id": "a160fd22c5c7ddc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T15:49:16.846989Z",
     "start_time": "2024-12-17T15:49:16.840082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "from librosa import feature \n",
    "import os\n",
    "\n",
    "def clean_audio(filename, folder_name, duration = 5, target_sr = 16000):\n",
    "    file_path = os.path.join(folder_name, filename)\n",
    "    y, sr = librosa.load(filename, sr=target_sr)\n",
    "    y = librosa.util.fix_length(y, size = target_sr * duration)\n",
    "    sf.write(file_path, y, target_sr)\n",
    "    return y\n",
    "\n",
    "clean_audio(\"5s20.wav\", \"/Users/25yoon/PycharmProjects/final_project/audios/5\")\n",
    "    "
   ],
   "id": "15b24d00f7cacc2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.0517578e-05, -3.0517578e-05,  4.8828125e-03, ...,\n",
       "       -4.5776367e-03, -4.0893555e-03, -4.5776367e-03], dtype=float32)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 229
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T20:12:03.969587Z",
     "start_time": "2024-12-17T20:11:58.731479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fn = \"7s20.wav\"\n",
    "record_audio(fn)\n",
    "clean_audio(fn, \"/Users/25yoon/PycharmProjects/final_project/audios/7\")"
   ],
   "id": "33f491916ae37421",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording audio for 5 seconds...\n",
      "Finished recording audio for 5 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-3.0517578e-05,  0.0000000e+00, -6.1035156e-05, ...,\n",
       "       -9.4604492e-04, -3.9672852e-04, -3.0517578e-05], dtype=float32)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 270
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T20:36:24.985526Z",
     "start_time": "2024-12-17T20:36:24.952595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "# function that extracts the mfcc\n",
    "\n",
    "\n",
    "def extract_mfcc(file_path, duration = 5, sampling_rate = 16000, n_mfcc = 40 ):\n",
    "    y, sr = librosa.load(file_path, sr=sampling_rate)\n",
    "    y = librosa.util.fix_length(y, size = sr * duration)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sampling_rate, n_mfcc=n_mfcc)\n",
    "    mfcc = mfcc - np.mean(mfcc, axis=1, keepdims=True) / np.std(mfcc, axis=1, keepdims=True)\n",
    "    mfcc = mfcc.T\n",
    "    return mfcc \n",
    "\n",
    "feature_sample = extract_mfcc(\"/Users/25yoon/PycharmProjects/final_project/test_audio_folders/test_2.wav\")\n",
    "print(f\"shape: {feature_sample.shape}\")\n",
    "\n"
   ],
   "id": "6957776142457e08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (157, 40)\n"
     ]
    }
   ],
   "execution_count": 272
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T01:15:51.826839Z",
     "start_time": "2024-12-17T01:15:51.337739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#standardizing is very important to z_scorizing all the values to make it easier for the machine to read \n",
    "scaler_1 = StandardScaler()\n",
    "def normalize(mfcc):\n",
    "    norm_mfcc = scaler_1.fit_transform(mfcc)\n",
    "    return norm_mfcc\n",
    "\n",
    "# might delete later\n",
    "def augment_audio(file_path, pitch_shift=2.0, output_folder=\"augmented_audio\"):\n",
    "    # Load the original audio file\n",
    "    y, sr = librosa.load(file_path, sr=16000)\n",
    "    \n",
    "    # Apply pitch shift\n",
    "    y_shifted = librosa.effects.pitch_shift(y, sr=sr, n_steps=pitch_shift)\n",
    "    \n",
    "    # Ensure the output folder exists (create it if it doesn't exist)\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Extract the filename from the original file path\n",
    "    filename = os.path.basename(file_path)\n",
    "    \n",
    "    # Create the new file name (e.g., \"user_1_01_augmented.wav\")\n",
    "    new_filename = f\"augmented_{filename}\"\n",
    "    # Create the full path to save the file\n",
    "    save_path = os.path.join(output_folder, new_filename)  \n",
    "    # Save the augmented audio file to the specified folder\n",
    "    sf.write(save_path, y_shifted, sr)  \n",
    "    print(f\"Saved augmented audio as {save_path}\")\n",
    "    return save_path\n"
   ],
   "id": "50d79950f271d7e5",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "check duration safety checking\n",
   "id": "a5e71c03d9c13ede"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T23:46:46.239401Z",
     "start_time": "2024-12-16T23:46:46.234441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wave\n",
    "\n",
    "with wave.open('test_2.wav', 'rb') as wav_file:\n",
    "    frame_rate = wav_file.getframerate()\n",
    "    n_frames = wav_file.getnframes()\n",
    "    duration = n_frames / frame_rate\n",
    "    print(f\"Duration: {duration} seconds\")"
   ],
   "id": "16b4eae3e5304be1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 10.0 seconds\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T04:58:08.521427Z",
     "start_time": "2024-12-18T04:58:07.778893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# audio preprocessing, file preprocessing\n",
    "X = []\n",
    "y = [] \n",
    "AUDIO_DIR = \"/Users/25yoon/PycharmProjects/final_project/audios\"\n",
    "\n",
    "for speaker_id, speaker_folder in enumerate(sorted(os.listdir(AUDIO_DIR))):\n",
    "    speaker_path = os.path.join(AUDIO_DIR, speaker_folder)\n",
    "    for audio_file in os.listdir(speaker_path):\n",
    "        file_path = os.path.join(speaker_path, audio_file)\n",
    "        mfcc = extract_mfcc(file_path, duration = 5, sampling_rate = 16000)\n",
    "        X.append(mfcc)\n",
    "        y.append(0 if speaker_id+1 < 7 else 1)\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        \n",
    "        \n"
   ],
   "id": "4efcb9da2357f6b5",
   "outputs": [],
   "execution_count": 302
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T04:58:11.724033Z",
     "start_time": "2024-12-18T04:58:11.713083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.makedirs('processed_data', exist_ok=True)\n",
    "np.save('processed_data/X_train.npy', X_train)\n",
    "np.save('processed_data/y_train.npy', y_train)\n",
    "np.save('processed_data/X_test.npy', X_test)\n",
    "np.save('processed_data/y_test.npy', y_test)"
   ],
   "id": "798c0bd621e6baa9",
   "outputs": [],
   "execution_count": 303
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T04:58:13.492078Z",
     "start_time": "2024-12-18T04:58:13.326116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# lstms, or long short term memories holds important information using three gates of input, forget, output \n",
    "def create_rnn_model(input_shape, num_users):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(32, return_sequences=False))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(num_users, activation='sigmoid'))  # One output neuron per user\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Model summary for input shape (80 time-steps, 40 features) for 10 users\n",
    "model = create_rnn_model(input_shape=(157, 40), num_users=7)\n",
    "model.summary()"
   ],
   "id": "4f19c3c10d774fdb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m157\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │        \u001B[38;5;34m26,880\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │        \u001B[38;5;34m12,416\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │         \u001B[38;5;34m1,056\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m7\u001B[0m)              │           \u001B[38;5;34m231\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">26,880</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">231</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m40,583\u001B[0m (158.53 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,583</span> (158.53 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m40,583\u001B[0m (158.53 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,583</span> (158.53 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 304
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T04:58:22.250904Z",
     "start_time": "2024-12-18T04:58:18.187611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ],
   "id": "fc6abea7f21319d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 106ms/step - accuracy: 0.0484 - loss: 2.2129 - val_accuracy: 0.1724 - val_loss: 1.9696\n",
      "Epoch 2/10\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 60ms/step - accuracy: 0.1289 - loss: 1.9754 - val_accuracy: 0.1724 - val_loss: 1.8343\n",
      "Epoch 3/10\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 58ms/step - accuracy: 0.1661 - loss: 1.8427 - val_accuracy: 0.1724 - val_loss: 1.7158\n",
      "Epoch 4/10\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step - accuracy: 0.1534 - loss: 1.7144 - val_accuracy: 0.2414 - val_loss: 1.5906\n",
      "Epoch 5/10\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 58ms/step - accuracy: 0.2545 - loss: 1.5789 - val_accuracy: 0.8276 - val_loss: 1.4571\n",
      "Epoch 6/10\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step - accuracy: 0.5116 - loss: 1.4412 - val_accuracy: 0.8276 - val_loss: 1.2993\n",
      "Epoch 7/10\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 62ms/step - accuracy: 0.7924 - loss: 1.2573 - val_accuracy: 0.8276 - val_loss: 1.1241\n",
      "Epoch 8/10\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 62ms/step - accuracy: 0.8089 - loss: 1.1290 - val_accuracy: 0.8276 - val_loss: 0.9426\n",
      "Epoch 9/10\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 60ms/step - accuracy: 0.8249 - loss: 0.9458 - val_accuracy: 0.8276 - val_loss: 0.7717\n",
      "Epoch 10/10\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 60ms/step - accuracy: 0.8314 - loss: 0.8087 - val_accuracy: 0.8276 - val_loss: 0.6381\n"
     ]
    }
   ],
   "execution_count": 305
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T06:07:17.813137Z",
     "start_time": "2024-12-18T06:07:17.710213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')"
   ],
   "id": "dbdb3e7d8edca02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.8276 - loss: 0.6381\n",
      "Test Loss: 0.6380565166473389, Test Accuracy: 0.8275862336158752\n"
     ]
    }
   ],
   "execution_count": 306
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:50:10.413807Z",
     "start_time": "2024-12-18T15:50:05.161911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def is_target_speaker(model, mfcc_features, precition=None):\n",
    "    prediction = model.predict(mfcc_features)\n",
    "    print(prediction)\n",
    "    prob = np.mean(prediction, axis=-1)\n",
    "    print(prob)\n",
    "    return prob[0] > 0.4  # Returns True (1) for target speaker, False (0) otherwise\n",
    "\n",
    "# Example MFCC extraction for new audio\n",
    "fn = \"test1impo.wav\"\n",
    "record_audio(fn)\n",
    "clean_audio(fn, \"/Users/25yoon/PycharmProjects/final_project/audios/7\")\n",
    "\n"
   ],
   "id": "6c6cd0ed0695ad53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording audio for 5 seconds...\n",
      "Finished recording audio for 5 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.0000000e+00, -3.0517578e-05,  3.0517578e-05, ...,\n",
       "        9.0026855e-02, -9.5520020e-03,  1.4300537e-01], dtype=float32)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 325
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T04:19:24.851309Z",
     "start_time": "2024-12-18T04:19:24.846335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fn = \"test1impo.wav\"\n",
    "record_audio(fn)\n",
    "clean_audio(fn, \"/Users/25yoon/PycharmProjects/final_project/audios/7\")"
   ],
   "id": "543c7e6500650b6f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 40)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 284
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "eb944d180d01dea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:50:31.071878Z",
     "start_time": "2024-12-18T15:50:30.845966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "new_mfcc = extract_mfcc('/Users/25yoon/PycharmProjects/final_project/audios/7/test1impo.wav')\n",
    "new_mfcc = np.expand_dims(new_mfcc, axis=0) \n",
    " # Extract the probability\n",
    "      # If > 0.5, grant access\n",
    "# Check if it matches the target speaker\n",
    "result = is_target_speaker(model, new_mfcc)\n",
    "if result:\n",
    "    print(\"Access granted\")\n",
    "else:\n",
    "    print(\"Access denied\")"
   ],
   "id": "d45f88cca58ff6a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 83ms/step\n",
      "[[0.8605667  0.62293994 0.13989203 0.17855164 0.4769474  0.1813635\n",
      "  0.33303502]]\n",
      "[0.39904234]\n",
      "Access denied\n"
     ]
    }
   ],
   "execution_count": 326
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T04:19:36.542406Z",
     "start_time": "2024-12-18T04:19:36.537718Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3f493b8311356503",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 40)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 285
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2677e84db8134caf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
